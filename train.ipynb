{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af7587a-f734-4fa6-af2a-372d40ee44de",
   "metadata": {},
   "source": [
    "## Training: Solar Panel Anomaly Detection on Thermal Orthophoto using Detectron2\n",
    "Register the training and validation datasets in COCO format, configure a Faster R-CNN model with 8 anomaly classes using Detectron2, and perform the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2202de-6cd8-448f-a3bd-b5765de7bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/04 22:00:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/04 22:00:10 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[08/04 22:00:10 d2.data.datasets.coco]: \u001b[0mLoaded 6924 images in COCO format from training_data\\data/train/annotations/result.json\n",
      "\u001b[32m[08/04 22:00:11 d2.data.build]: \u001b[0mRemoved 7 images with no usable annotations. 6917 images left.\n",
      "\u001b[32m[08/04 22:00:11 d2.data.build]: \u001b[0mDistribution of instances among all 20 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   Single   | 357          |  Hotspot   | 969          |   Multi    | 5081         |\n",
      "|  Hotspots  | 2978         |   Single   | 1844         |   Diode    | 7311         |\n",
      "|   Multi    | 1197         |   Diode    | 108          |   Single   | 0            |\n",
      "|  Bypassed  | 0            | Substring  | 0            |   Multi    | 0            |\n",
      "|  Bypassed  | 0            | Substring  | 0            |   String   | 0            |\n",
      "|   (Open    | 0            |  Circuit)  | 0            |   String   | 0            |\n",
      "| (Reversed  | 0            | Polarity)  | 0            |            |              |\n",
      "|   total    | 19845        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[08/04 22:00:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/04 22:00:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/04 22:00:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[08/04 22:00:11 d2.data.common]: \u001b[0mSerializing 6917 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/04 22:00:11 d2.data.common]: \u001b[0mSerialized dataset takes 4.45 MiB\n",
      "\u001b[32m[08/04 22:00:11 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[08/04 22:00:11 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_280758.pkl: 167MB [00:42, 3.96MB/s]                                                                        \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (9, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (9,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (32, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (32,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/04 22:00:53 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\.conda\\envs\\thermal-detector\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/04 22:01:02 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 19  total_loss: 2.729  loss_cls: 2.275  loss_box_reg: 0.1334  loss_rpn_cls: 0.2333  loss_rpn_loc: 0.01895    time: 0.1873  last_time: 0.1934  data_time: 0.1728  last_data_time: 0.0016   lr: 4.9953e-06  max_mem: 1736M\n",
      "\u001b[32m[08/04 22:01:06 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 39  total_loss: 2.484  loss_cls: 2.041  loss_box_reg: 0.08088  loss_rpn_cls: 0.2409  loss_rpn_loc: 0.01998    time: 0.1929  last_time: 0.1781  data_time: 0.0016  last_data_time: 0.0016   lr: 9.9902e-06  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:10 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 59  total_loss: 2.312  loss_cls: 1.569  loss_box_reg: 0.06594  loss_rpn_cls: 0.3841  loss_rpn_loc: 0.03076    time: 0.1932  last_time: 0.1859  data_time: 0.0016  last_data_time: 0.0019   lr: 1.4985e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:14 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 79  total_loss: 1.492  loss_cls: 1.08  loss_box_reg: 0.1441  loss_rpn_cls: 0.2648  loss_rpn_loc: 0.0282    time: 0.1936  last_time: 0.2113  data_time: 0.0016  last_data_time: 0.0015   lr: 1.998e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:18 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 99  total_loss: 0.9286  loss_cls: 0.6235  loss_box_reg: 0.1251  loss_rpn_cls: 0.1547  loss_rpn_loc: 0.0193    time: 0.1944  last_time: 0.1703  data_time: 0.0016  last_data_time: 0.0015   lr: 2.4975e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:22 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 119  total_loss: 1.069  loss_cls: 0.5928  loss_box_reg: 0.2627  loss_rpn_cls: 0.2088  loss_rpn_loc: 0.02417    time: 0.1970  last_time: 0.2140  data_time: 0.0017  last_data_time: 0.0016   lr: 2.997e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:26 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 139  total_loss: 0.9277  loss_cls: 0.4929  loss_box_reg: 0.2649  loss_rpn_cls: 0.1779  loss_rpn_loc: 0.02729    time: 0.1979  last_time: 0.2108  data_time: 0.0016  last_data_time: 0.0014   lr: 3.4965e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:31 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 159  total_loss: 0.7304  loss_cls: 0.3784  loss_box_reg: 0.1483  loss_rpn_cls: 0.08545  loss_rpn_loc: 0.01628    time: 0.2020  last_time: 0.2080  data_time: 0.0017  last_data_time: 0.0016   lr: 3.996e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:35 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 179  total_loss: 0.9186  loss_cls: 0.4751  loss_box_reg: 0.2727  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.0167    time: 0.2039  last_time: 0.1900  data_time: 0.0017  last_data_time: 0.0019   lr: 4.4955e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:40 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 199  total_loss: 0.9552  loss_cls: 0.4948  loss_box_reg: 0.3098  loss_rpn_cls: 0.05834  loss_rpn_loc: 0.01257    time: 0.2047  last_time: 0.2045  data_time: 0.0016  last_data_time: 0.0015   lr: 4.995e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:44 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 219  total_loss: 0.9404  loss_cls: 0.4993  loss_box_reg: 0.3255  loss_rpn_cls: 0.07253  loss_rpn_loc: 0.01607    time: 0.2056  last_time: 0.2217  data_time: 0.0016  last_data_time: 0.0015   lr: 5.4945e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:48 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 239  total_loss: 0.7646  loss_cls: 0.3951  loss_box_reg: 0.2644  loss_rpn_cls: 0.06263  loss_rpn_loc: 0.02103    time: 0.2065  last_time: 0.2132  data_time: 0.0017  last_data_time: 0.0017   lr: 5.994e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:53 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 259  total_loss: 0.8885  loss_cls: 0.5146  loss_box_reg: 0.3475  loss_rpn_cls: 0.03877  loss_rpn_loc: 0.01447    time: 0.2072  last_time: 0.2330  data_time: 0.0017  last_data_time: 0.0016   lr: 6.4935e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:01:57 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 279  total_loss: 1.046  loss_cls: 0.4754  loss_box_reg: 0.2898  loss_rpn_cls: 0.08248  loss_rpn_loc: 0.02462    time: 0.2091  last_time: 0.1957  data_time: 0.0016  last_data_time: 0.0017   lr: 6.993e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:02:02 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 299  total_loss: 0.9209  loss_cls: 0.4653  loss_box_reg: 0.3587  loss_rpn_cls: 0.04895  loss_rpn_loc: 0.01596    time: 0.2098  last_time: 0.2111  data_time: 0.0016  last_data_time: 0.0015   lr: 7.4925e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:02:06 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 319  total_loss: 1.038  loss_cls: 0.511  loss_box_reg: 0.4812  loss_rpn_cls: 0.05568  loss_rpn_loc: 0.01182    time: 0.2103  last_time: 0.2369  data_time: 0.0016  last_data_time: 0.0013   lr: 7.992e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:02:10 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 339  total_loss: 1.173  loss_cls: 0.5878  loss_box_reg: 0.417  loss_rpn_cls: 0.0771  loss_rpn_loc: 0.02862    time: 0.2105  last_time: 0.2062  data_time: 0.0017  last_data_time: 0.0018   lr: 8.4915e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:02:15 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 359  total_loss: 0.9397  loss_cls: 0.4755  loss_box_reg: 0.3792  loss_rpn_cls: 0.04257  loss_rpn_loc: 0.01304    time: 0.2109  last_time: 0.2061  data_time: 0.0017  last_data_time: 0.0015   lr: 8.991e-05  max_mem: 1737M\n",
      "\u001b[32m[08/04 22:02:19 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 379  total_loss: 1.156  loss_cls: 0.6235  loss_box_reg: 0.4725  loss_rpn_cls: 0.03499  loss_rpn_loc: 0.0151    time: 0.2112  last_time: 0.2306  data_time: 0.0016  last_data_time: 0.0014   lr: 9.4905e-05  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:02:23 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 399  total_loss: 1.15  loss_cls: 0.5607  loss_box_reg: 0.5014  loss_rpn_cls: 0.06276  loss_rpn_loc: 0.0133    time: 0.2115  last_time: 0.3311  data_time: 0.0017  last_data_time: 0.0016   lr: 9.99e-05  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:02:28 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 419  total_loss: 1.114  loss_cls: 0.5676  loss_box_reg: 0.4424  loss_rpn_cls: 0.05057  loss_rpn_loc: 0.01804    time: 0.2123  last_time: 0.2304  data_time: 0.0017  last_data_time: 0.0018   lr: 0.0001049  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:02:33 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 439  total_loss: 1.085  loss_cls: 0.5269  loss_box_reg: 0.4672  loss_rpn_cls: 0.031  loss_rpn_loc: 0.0179    time: 0.2131  last_time: 0.2539  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00010989  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:02:37 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 459  total_loss: 1.268  loss_cls: 0.594  loss_box_reg: 0.5086  loss_rpn_cls: 0.04745  loss_rpn_loc: 0.01996    time: 0.2135  last_time: 0.2211  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00011489  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:02:42 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 479  total_loss: 1.018  loss_cls: 0.486  loss_box_reg: 0.4828  loss_rpn_cls: 0.03478  loss_rpn_loc: 0.01016    time: 0.2140  last_time: 0.2246  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00011988  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:02:46 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 499  total_loss: 1.094  loss_cls: 0.4774  loss_box_reg: 0.4611  loss_rpn_cls: 0.04831  loss_rpn_loc: 0.01318    time: 0.2146  last_time: 0.2083  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00012488  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:02:51 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 519  total_loss: 1.053  loss_cls: 0.5023  loss_box_reg: 0.4478  loss_rpn_cls: 0.04412  loss_rpn_loc: 0.01296    time: 0.2149  last_time: 0.2009  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00012987  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:02:55 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 539  total_loss: 0.9127  loss_cls: 0.4181  loss_box_reg: 0.4634  loss_rpn_cls: 0.0529  loss_rpn_loc: 0.01104    time: 0.2155  last_time: 0.2224  data_time: 0.0017  last_data_time: 0.0020   lr: 0.00013487  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:00 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 559  total_loss: 1.08  loss_cls: 0.4842  loss_box_reg: 0.5366  loss_rpn_cls: 0.0431  loss_rpn_loc: 0.01636    time: 0.2161  last_time: 0.2316  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00013986  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:05 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 579  total_loss: 1.102  loss_cls: 0.5004  loss_box_reg: 0.5403  loss_rpn_cls: 0.0423  loss_rpn_loc: 0.01319    time: 0.2167  last_time: 0.2384  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00014486  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:10 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 599  total_loss: 1.254  loss_cls: 0.5438  loss_box_reg: 0.5373  loss_rpn_cls: 0.03573  loss_rpn_loc: 0.01252    time: 0.2181  last_time: 0.2382  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00014985  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:14 d2.utils.events]: \u001b[0m eta: 0:08:36  iter: 619  total_loss: 0.8881  loss_cls: 0.4172  loss_box_reg: 0.4392  loss_rpn_cls: 0.05979  loss_rpn_loc: 0.01193    time: 0.2184  last_time: 0.2431  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00015485  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:19 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 639  total_loss: 1.131  loss_cls: 0.5221  loss_box_reg: 0.5491  loss_rpn_cls: 0.03262  loss_rpn_loc: 0.01056    time: 0.2187  last_time: 0.2341  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00015984  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:24 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 659  total_loss: 1.014  loss_cls: 0.4864  loss_box_reg: 0.4827  loss_rpn_cls: 0.02758  loss_rpn_loc: 0.01037    time: 0.2190  last_time: 0.2615  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00016484  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:28 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 679  total_loss: 1.19  loss_cls: 0.5448  loss_box_reg: 0.5302  loss_rpn_cls: 0.02466  loss_rpn_loc: 0.01691    time: 0.2195  last_time: 0.2161  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00016983  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:33 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 699  total_loss: 1.125  loss_cls: 0.4912  loss_box_reg: 0.5919  loss_rpn_cls: 0.02437  loss_rpn_loc: 0.009304    time: 0.2198  last_time: 0.1964  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00017483  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:38 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 719  total_loss: 1.133  loss_cls: 0.5303  loss_box_reg: 0.5633  loss_rpn_cls: 0.02474  loss_rpn_loc: 0.01877    time: 0.2204  last_time: 0.2505  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00017982  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:42 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 739  total_loss: 1.203  loss_cls: 0.49  loss_box_reg: 0.4634  loss_rpn_cls: 0.05411  loss_rpn_loc: 0.01351    time: 0.2208  last_time: 0.3967  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00018482  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:47 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 759  total_loss: 1.009  loss_cls: 0.5014  loss_box_reg: 0.4663  loss_rpn_cls: 0.02707  loss_rpn_loc: 0.02203    time: 0.2211  last_time: 0.1926  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00018981  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:52 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 779  total_loss: 1.153  loss_cls: 0.4852  loss_box_reg: 0.5982  loss_rpn_cls: 0.02415  loss_rpn_loc: 0.01286    time: 0.2214  last_time: 0.2160  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00019481  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:03:56 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 799  total_loss: 1.241  loss_cls: 0.5541  loss_box_reg: 0.5963  loss_rpn_cls: 0.04447  loss_rpn_loc: 0.03256    time: 0.2218  last_time: 0.2025  data_time: 0.0017  last_data_time: 0.0018   lr: 0.0001998  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:01 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 819  total_loss: 1.101  loss_cls: 0.5198  loss_box_reg: 0.5487  loss_rpn_cls: 0.03555  loss_rpn_loc: 0.008857    time: 0.2220  last_time: 0.2224  data_time: 0.0017  last_data_time: 0.0017   lr: 0.0002048  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:06 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 839  total_loss: 1.099  loss_cls: 0.5374  loss_box_reg: 0.544  loss_rpn_cls: 0.01856  loss_rpn_loc: 0.01156    time: 0.2224  last_time: 0.2241  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00020979  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:11 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 859  total_loss: 0.9065  loss_cls: 0.3991  loss_box_reg: 0.3978  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.01097    time: 0.2231  last_time: 0.4133  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00021479  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:16 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 879  total_loss: 0.8928  loss_cls: 0.4443  loss_box_reg: 0.4275  loss_rpn_cls: 0.02782  loss_rpn_loc: 0.01486    time: 0.2236  last_time: 0.2750  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00021978  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:20 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 899  total_loss: 1.066  loss_cls: 0.4754  loss_box_reg: 0.5502  loss_rpn_cls: 0.02142  loss_rpn_loc: 0.01252    time: 0.2237  last_time: 0.2652  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00022478  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:25 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 919  total_loss: 1.004  loss_cls: 0.4509  loss_box_reg: 0.4813  loss_rpn_cls: 0.02132  loss_rpn_loc: 0.01341    time: 0.2241  last_time: 0.2414  data_time: 0.0018  last_data_time: 0.0015   lr: 0.00022977  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:30 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 939  total_loss: 0.9415  loss_cls: 0.4249  loss_box_reg: 0.4321  loss_rpn_cls: 0.02699  loss_rpn_loc: 0.01148    time: 0.2247  last_time: 0.2614  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00023477  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:35 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 959  total_loss: 0.8157  loss_cls: 0.3674  loss_box_reg: 0.4397  loss_rpn_cls: 0.02458  loss_rpn_loc: 0.01186    time: 0.2249  last_time: 0.2320  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00023976  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:40 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 979  total_loss: 1.021  loss_cls: 0.4842  loss_box_reg: 0.4275  loss_rpn_cls: 0.02632  loss_rpn_loc: 0.01552    time: 0.2251  last_time: 0.2631  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00024476  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:45 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 999  total_loss: 0.9913  loss_cls: 0.4581  loss_box_reg: 0.4954  loss_rpn_cls: 0.02703  loss_rpn_loc: 0.01009    time: 0.2255  last_time: 0.2569  data_time: 0.0016  last_data_time: 0.0017   lr: 0.00024975  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:49 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 1019  total_loss: 0.9178  loss_cls: 0.3906  loss_box_reg: 0.4384  loss_rpn_cls: 0.02642  loss_rpn_loc: 0.006267    time: 0.2258  last_time: 0.1894  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:54 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 1039  total_loss: 0.7965  loss_cls: 0.3927  loss_box_reg: 0.3518  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.008913    time: 0.2261  last_time: 0.2518  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:04:59 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 1059  total_loss: 0.815  loss_cls: 0.357  loss_box_reg: 0.3758  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.009998    time: 0.2262  last_time: 0.2591  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:04 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 1079  total_loss: 0.8796  loss_cls: 0.3425  loss_box_reg: 0.4052  loss_rpn_cls: 0.01793  loss_rpn_loc: 0.01081    time: 0.2266  last_time: 0.2636  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:09 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 1099  total_loss: 0.8909  loss_cls: 0.4355  loss_box_reg: 0.4182  loss_rpn_cls: 0.02668  loss_rpn_loc: 0.01361    time: 0.2272  last_time: 0.2421  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:14 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 1119  total_loss: 0.6938  loss_cls: 0.3438  loss_box_reg: 0.3553  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.007733    time: 0.2274  last_time: 0.2248  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:19 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 1139  total_loss: 0.7602  loss_cls: 0.3554  loss_box_reg: 0.3932  loss_rpn_cls: 0.009165  loss_rpn_loc: 0.007034    time: 0.2276  last_time: 0.2706  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:23 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1159  total_loss: 0.8699  loss_cls: 0.4108  loss_box_reg: 0.4005  loss_rpn_cls: 0.02387  loss_rpn_loc: 0.01104    time: 0.2279  last_time: 0.2169  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:28 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 1179  total_loss: 0.7652  loss_cls: 0.37  loss_box_reg: 0.3359  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.01204    time: 0.2281  last_time: 0.2650  data_time: 0.0015  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:33 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 1199  total_loss: 0.8114  loss_cls: 0.4169  loss_box_reg: 0.3159  loss_rpn_cls: 0.02094  loss_rpn_loc: 0.009533    time: 0.2286  last_time: 0.2999  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:38 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 1219  total_loss: 0.8345  loss_cls: 0.3574  loss_box_reg: 0.4217  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.009582    time: 0.2289  last_time: 0.3124  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:44 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1239  total_loss: 0.7894  loss_cls: 0.4126  loss_box_reg: 0.3392  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.008875    time: 0.2296  last_time: 0.3852  data_time: 0.0016  last_data_time: 0.0014   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:49 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 1259  total_loss: 0.8872  loss_cls: 0.4077  loss_box_reg: 0.4115  loss_rpn_cls: 0.03008  loss_rpn_loc: 0.01486    time: 0.2300  last_time: 0.2335  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:54 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 1279  total_loss: 0.6173  loss_cls: 0.2982  loss_box_reg: 0.3187  loss_rpn_cls: 0.01324  loss_rpn_loc: 0.007736    time: 0.2303  last_time: 0.2356  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:05:59 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 1299  total_loss: 0.7253  loss_cls: 0.2765  loss_box_reg: 0.3632  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.01151    time: 0.2309  last_time: 0.3252  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:04 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1319  total_loss: 0.7925  loss_cls: 0.3839  loss_box_reg: 0.3613  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.008722    time: 0.2311  last_time: 0.2424  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:09 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1339  total_loss: 0.882  loss_cls: 0.4462  loss_box_reg: 0.3674  loss_rpn_cls: 0.02969  loss_rpn_loc: 0.01762    time: 0.2314  last_time: 0.2307  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:14 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1359  total_loss: 0.724  loss_cls: 0.3509  loss_box_reg: 0.309  loss_rpn_cls: 0.03501  loss_rpn_loc: 0.01326    time: 0.2314  last_time: 0.2332  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:19 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 1379  total_loss: 0.8194  loss_cls: 0.3734  loss_box_reg: 0.43  loss_rpn_cls: 0.02048  loss_rpn_loc: 0.01308    time: 0.2314  last_time: 0.2468  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:23 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 1399  total_loss: 0.8578  loss_cls: 0.4099  loss_box_reg: 0.3746  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.01353    time: 0.2316  last_time: 0.2580  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:28 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 1419  total_loss: 0.8027  loss_cls: 0.3822  loss_box_reg: 0.3691  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.01051    time: 0.2317  last_time: 0.2188  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:33 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1439  total_loss: 0.71  loss_cls: 0.3623  loss_box_reg: 0.3138  loss_rpn_cls: 0.023  loss_rpn_loc: 0.008909    time: 0.2321  last_time: 0.2319  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:38 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1459  total_loss: 0.7457  loss_cls: 0.3304  loss_box_reg: 0.3202  loss_rpn_cls: 0.02195  loss_rpn_loc: 0.009385    time: 0.2322  last_time: 0.2437  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:43 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 1479  total_loss: 0.651  loss_cls: 0.3325  loss_box_reg: 0.3319  loss_rpn_cls: 0.03211  loss_rpn_loc: 0.01258    time: 0.2324  last_time: 0.2703  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:48 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1499  total_loss: 0.7569  loss_cls: 0.3499  loss_box_reg: 0.3258  loss_rpn_cls: 0.02651  loss_rpn_loc: 0.01138    time: 0.2327  last_time: 0.2814  data_time: 0.0016  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:53 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1519  total_loss: 0.6902  loss_cls: 0.3012  loss_box_reg: 0.3612  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.01135    time: 0.2328  last_time: 0.2419  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:06:58 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 1539  total_loss: 0.5389  loss_cls: 0.2362  loss_box_reg: 0.2592  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.008642    time: 0.2330  last_time: 0.2621  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:03 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 1559  total_loss: 0.7343  loss_cls: 0.3382  loss_box_reg: 0.2999  loss_rpn_cls: 0.02243  loss_rpn_loc: 0.008728    time: 0.2331  last_time: 0.2555  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:08 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 1579  total_loss: 0.8159  loss_cls: 0.4112  loss_box_reg: 0.3346  loss_rpn_cls: 0.02286  loss_rpn_loc: 0.007876    time: 0.2332  last_time: 0.2254  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:13 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1599  total_loss: 0.7213  loss_cls: 0.3264  loss_box_reg: 0.3414  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.007424    time: 0.2335  last_time: 0.2412  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:18 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 1619  total_loss: 0.9816  loss_cls: 0.346  loss_box_reg: 0.4966  loss_rpn_cls: 0.02335  loss_rpn_loc: 0.01503    time: 0.2337  last_time: 0.2442  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:23 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 1639  total_loss: 0.7115  loss_cls: 0.3374  loss_box_reg: 0.3148  loss_rpn_cls: 0.01814  loss_rpn_loc: 0.009217    time: 0.2340  last_time: 0.2838  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:28 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1659  total_loss: 0.708  loss_cls: 0.3094  loss_box_reg: 0.3305  loss_rpn_cls: 0.03079  loss_rpn_loc: 0.01783    time: 0.2340  last_time: 0.2311  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:33 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 1679  total_loss: 0.7645  loss_cls: 0.3213  loss_box_reg: 0.3125  loss_rpn_cls: 0.0254  loss_rpn_loc: 0.01505    time: 0.2344  last_time: 0.5312  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:39 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 1699  total_loss: 0.7671  loss_cls: 0.3352  loss_box_reg: 0.3001  loss_rpn_cls: 0.01436  loss_rpn_loc: 0.01046    time: 0.2348  last_time: 0.2387  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:44 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 1719  total_loss: 0.6637  loss_cls: 0.3489  loss_box_reg: 0.3275  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.00915    time: 0.2350  last_time: 0.2243  data_time: 0.0018  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:49 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 1739  total_loss: 0.7222  loss_cls: 0.3354  loss_box_reg: 0.3594  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.01024    time: 0.2352  last_time: 0.2351  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:54 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 1759  total_loss: 0.7202  loss_cls: 0.3308  loss_box_reg: 0.3165  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.009788    time: 0.2353  last_time: 0.2230  data_time: 0.0018  last_data_time: 0.0014   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:07:59 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 1779  total_loss: 0.6456  loss_cls: 0.3797  loss_box_reg: 0.283  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.01086    time: 0.2356  last_time: 0.3644  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:04 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 1799  total_loss: 0.5759  loss_cls: 0.2843  loss_box_reg: 0.2615  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.01137    time: 0.2356  last_time: 0.1996  data_time: 0.0016  last_data_time: 0.0014   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:08 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 1819  total_loss: 0.7116  loss_cls: 0.347  loss_box_reg: 0.3307  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.01001    time: 0.2358  last_time: 0.2844  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:14 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 1839  total_loss: 0.6844  loss_cls: 0.3481  loss_box_reg: 0.3275  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.0091    time: 0.2359  last_time: 0.2454  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:19 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1859  total_loss: 0.6901  loss_cls: 0.3884  loss_box_reg: 0.2793  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.01027    time: 0.2362  last_time: 0.2436  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:23 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 1879  total_loss: 0.7283  loss_cls: 0.3444  loss_box_reg: 0.3292  loss_rpn_cls: 0.02496  loss_rpn_loc: 0.01275    time: 0.2362  last_time: 0.2390  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:29 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 1899  total_loss: 0.836  loss_cls: 0.3678  loss_box_reg: 0.3907  loss_rpn_cls: 0.02364  loss_rpn_loc: 0.01359    time: 0.2364  last_time: 0.3031  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:34 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 1919  total_loss: 0.7061  loss_cls: 0.3582  loss_box_reg: 0.2858  loss_rpn_cls: 0.02656  loss_rpn_loc: 0.01518    time: 0.2366  last_time: 0.2650  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:39 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 1939  total_loss: 0.7636  loss_cls: 0.3079  loss_box_reg: 0.3175  loss_rpn_cls: 0.02256  loss_rpn_loc: 0.01185    time: 0.2369  last_time: 0.2764  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:44 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 1959  total_loss: 0.7726  loss_cls: 0.4477  loss_box_reg: 0.3615  loss_rpn_cls: 0.02711  loss_rpn_loc: 0.009998    time: 0.2371  last_time: 0.2428  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:50 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 1979  total_loss: 0.6423  loss_cls: 0.3427  loss_box_reg: 0.3158  loss_rpn_cls: 0.02076  loss_rpn_loc: 0.01169    time: 0.2375  last_time: 0.2378  data_time: 0.0018  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:08:55 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 1999  total_loss: 0.6573  loss_cls: 0.2639  loss_box_reg: 0.3657  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.008526    time: 0.2376  last_time: 0.2380  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:00 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 2019  total_loss: 0.5975  loss_cls: 0.3062  loss_box_reg: 0.3059  loss_rpn_cls: 0.009869  loss_rpn_loc: 0.007738    time: 0.2377  last_time: 0.2461  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:05 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 2039  total_loss: 0.797  loss_cls: 0.3702  loss_box_reg: 0.3428  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.008667    time: 0.2379  last_time: 0.2058  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:10 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 2059  total_loss: 0.7047  loss_cls: 0.3655  loss_box_reg: 0.3372  loss_rpn_cls: 0.01838  loss_rpn_loc: 0.01321    time: 0.2380  last_time: 0.3001  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:15 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 2079  total_loss: 0.6461  loss_cls: 0.3044  loss_box_reg: 0.2713  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.008647    time: 0.2381  last_time: 0.2505  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:20 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 2099  total_loss: 0.6675  loss_cls: 0.2954  loss_box_reg: 0.3368  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.01281    time: 0.2383  last_time: 0.2750  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:25 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 2119  total_loss: 0.7424  loss_cls: 0.3535  loss_box_reg: 0.3357  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.009913    time: 0.2386  last_time: 0.2365  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:30 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 2139  total_loss: 0.7481  loss_cls: 0.365  loss_box_reg: 0.3199  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01209    time: 0.2387  last_time: 0.2469  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:36 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 2159  total_loss: 0.7364  loss_cls: 0.3729  loss_box_reg: 0.3603  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.00847    time: 0.2392  last_time: 0.2329  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:41 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 2179  total_loss: 0.7906  loss_cls: 0.3661  loss_box_reg: 0.3179  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.009896    time: 0.2392  last_time: 0.2274  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:46 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 2199  total_loss: 0.553  loss_cls: 0.2702  loss_box_reg: 0.2728  loss_rpn_cls: 0.009988  loss_rpn_loc: 0.009449    time: 0.2394  last_time: 0.2930  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:51 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 2219  total_loss: 0.6778  loss_cls: 0.2999  loss_box_reg: 0.3476  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.008976    time: 0.2396  last_time: 0.2894  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:09:56 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 2239  total_loss: 0.8162  loss_cls: 0.3404  loss_box_reg: 0.3662  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.01334    time: 0.2397  last_time: 0.2380  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:02 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 2259  total_loss: 0.5829  loss_cls: 0.3027  loss_box_reg: 0.2645  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.008796    time: 0.2398  last_time: 0.2308  data_time: 0.0017  last_data_time: 0.0013   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:07 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 2279  total_loss: 0.6638  loss_cls: 0.2906  loss_box_reg: 0.3128  loss_rpn_cls: 0.009274  loss_rpn_loc: 0.008675    time: 0.2400  last_time: 0.2459  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:12 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 2299  total_loss: 0.6938  loss_cls: 0.3199  loss_box_reg: 0.3301  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.009733    time: 0.2402  last_time: 0.3157  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:17 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 2319  total_loss: 0.6209  loss_cls: 0.3105  loss_box_reg: 0.3365  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.01034    time: 0.2405  last_time: 0.2213  data_time: 0.0018  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:23 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 2339  total_loss: 0.6208  loss_cls: 0.2494  loss_box_reg: 0.3106  loss_rpn_cls: 0.00803  loss_rpn_loc: 0.00592    time: 0.2406  last_time: 0.2468  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:28 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 2359  total_loss: 0.6643  loss_cls: 0.2488  loss_box_reg: 0.3322  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.01131    time: 0.2408  last_time: 0.2359  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:33 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 2379  total_loss: 0.7122  loss_cls: 0.3351  loss_box_reg: 0.3486  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.008543    time: 0.2409  last_time: 0.2619  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:38 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 2399  total_loss: 0.6876  loss_cls: 0.3053  loss_box_reg: 0.3265  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01089    time: 0.2410  last_time: 0.2482  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:43 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 2419  total_loss: 0.618  loss_cls: 0.2965  loss_box_reg: 0.2954  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.009787    time: 0.2412  last_time: 0.2666  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:48 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 2439  total_loss: 0.7235  loss_cls: 0.3392  loss_box_reg: 0.3353  loss_rpn_cls: 0.02586  loss_rpn_loc: 0.009716    time: 0.2413  last_time: 0.2652  data_time: 0.0017  last_data_time: 0.0013   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:54 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 2459  total_loss: 0.628  loss_cls: 0.3166  loss_box_reg: 0.294  loss_rpn_cls: 0.01963  loss_rpn_loc: 0.008275    time: 0.2415  last_time: 0.3796  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:10:59 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 2479  total_loss: 0.7895  loss_cls: 0.3383  loss_box_reg: 0.3815  loss_rpn_cls: 0.02269  loss_rpn_loc: 0.01778    time: 0.2416  last_time: 0.2546  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:04 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 2499  total_loss: 0.5767  loss_cls: 0.2435  loss_box_reg: 0.267  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.01451    time: 0.2418  last_time: 0.2595  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:09 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 2519  total_loss: 0.7578  loss_cls: 0.3162  loss_box_reg: 0.3835  loss_rpn_cls: 0.0215  loss_rpn_loc: 0.01398    time: 0.2419  last_time: 0.2143  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:14 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 2539  total_loss: 0.8439  loss_cls: 0.4195  loss_box_reg: 0.3608  loss_rpn_cls: 0.02603  loss_rpn_loc: 0.017    time: 0.2420  last_time: 0.2808  data_time: 0.0017  last_data_time: 0.0020   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:19 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 2559  total_loss: 0.675  loss_cls: 0.3274  loss_box_reg: 0.3206  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.007227    time: 0.2421  last_time: 0.2860  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:24 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 2579  total_loss: 0.6354  loss_cls: 0.2879  loss_box_reg: 0.2955  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.009031    time: 0.2422  last_time: 0.2861  data_time: 0.0016  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:29 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 2599  total_loss: 0.5836  loss_cls: 0.2657  loss_box_reg: 0.2712  loss_rpn_cls: 0.0108  loss_rpn_loc: 0.01002    time: 0.2422  last_time: 0.2636  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:35 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 2619  total_loss: 0.794  loss_cls: 0.3678  loss_box_reg: 0.4408  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.009575    time: 0.2423  last_time: 0.2684  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:40 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 2639  total_loss: 0.6144  loss_cls: 0.3331  loss_box_reg: 0.3211  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.009929    time: 0.2425  last_time: 0.2592  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:45 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 2659  total_loss: 0.6892  loss_cls: 0.3925  loss_box_reg: 0.3181  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.007757    time: 0.2426  last_time: 0.2393  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:50 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 2679  total_loss: 0.5996  loss_cls: 0.2463  loss_box_reg: 0.2581  loss_rpn_cls: 0.009111  loss_rpn_loc: 0.007536    time: 0.2428  last_time: 0.2738  data_time: 0.0018  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:11:56 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 2699  total_loss: 0.6308  loss_cls: 0.2652  loss_box_reg: 0.3044  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.009388    time: 0.2429  last_time: 0.2829  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:01 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 2719  total_loss: 0.6727  loss_cls: 0.3308  loss_box_reg: 0.321  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.007478    time: 0.2432  last_time: 0.5246  data_time: 0.0018  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:07 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 2739  total_loss: 0.6538  loss_cls: 0.3067  loss_box_reg: 0.2774  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.009969    time: 0.2434  last_time: 0.2748  data_time: 0.0017  last_data_time: 0.0020   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:12 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 2759  total_loss: 0.5624  loss_cls: 0.2423  loss_box_reg: 0.291  loss_rpn_cls: 0.009225  loss_rpn_loc: 0.009722    time: 0.2435  last_time: 0.2576  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:17 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 2779  total_loss: 0.6569  loss_cls: 0.2699  loss_box_reg: 0.3991  loss_rpn_cls: 0.007667  loss_rpn_loc: 0.009834    time: 0.2437  last_time: 0.2465  data_time: 0.0017  last_data_time: 0.0014   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:22 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 2799  total_loss: 0.7833  loss_cls: 0.3312  loss_box_reg: 0.396  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.01109    time: 0.2438  last_time: 0.2224  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:28 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 2819  total_loss: 0.5821  loss_cls: 0.3042  loss_box_reg: 0.2866  loss_rpn_cls: 0.008651  loss_rpn_loc: 0.00899    time: 0.2440  last_time: 0.2403  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:33 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 2839  total_loss: 0.6919  loss_cls: 0.2987  loss_box_reg: 0.329  loss_rpn_cls: 0.01782  loss_rpn_loc: 0.01189    time: 0.2440  last_time: 0.2891  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:38 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 2859  total_loss: 0.7025  loss_cls: 0.3094  loss_box_reg: 0.2927  loss_rpn_cls: 0.01702  loss_rpn_loc: 0.01001    time: 0.2441  last_time: 0.2052  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:44 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 2879  total_loss: 0.6194  loss_cls: 0.2555  loss_box_reg: 0.3203  loss_rpn_cls: 0.006268  loss_rpn_loc: 0.00878    time: 0.2443  last_time: 0.2247  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:49 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 2899  total_loss: 0.6661  loss_cls: 0.3439  loss_box_reg: 0.302  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.007519    time: 0.2445  last_time: 0.2430  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:12:54 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 2919  total_loss: 0.7451  loss_cls: 0.32  loss_box_reg: 0.373  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.015    time: 0.2447  last_time: 0.2166  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:13:00 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2939  total_loss: 0.6761  loss_cls: 0.2815  loss_box_reg: 0.3577  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.008741    time: 0.2449  last_time: 0.5530  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:13:05 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 2959  total_loss: 0.6478  loss_cls: 0.2749  loss_box_reg: 0.269  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.009194    time: 0.2450  last_time: 0.2147  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:13:10 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2979  total_loss: 0.6313  loss_cls: 0.3349  loss_box_reg: 0.2797  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.007578    time: 0.2451  last_time: 0.2539  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:13:16 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.6497  loss_cls: 0.2647  loss_box_reg: 0.2722  loss_rpn_cls: 0.005739  loss_rpn_loc: 0.006542    time: 0.2453  last_time: 0.2776  data_time: 0.0018  last_data_time: 0.0015   lr: 0.00025  max_mem: 1738M\n",
      "\u001b[32m[08/04 22:13:16 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:12:15 (0.2453 s / it)\n",
      "\u001b[32m[08/04 22:13:16 d2.engine.hooks]: \u001b[0mTotal training time: 0:12:17 (0:00:02 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/04 22:13:16 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[08/04 22:13:16 d2.data.datasets.coco]: \u001b[0mLoaded 400 images in COCO format from training_data\\data/valid/annotations/result.json\n",
      "\u001b[32m[08/04 22:13:16 d2.data.build]: \u001b[0mDistribution of instances among all 20 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   Single   | 34           |  Hotspot   | 77           |   Multi    | 209          |\n",
      "|  Hotspots  | 263          |   Single   | 128          |   Diode    | 323          |\n",
      "|   Multi    | 69           |   Diode    | 16           |   Single   | 0            |\n",
      "|  Bypassed  | 0            | Substring  | 0            |   Multi    | 0            |\n",
      "|  Bypassed  | 0            | Substring  | 0            |   String   | 0            |\n",
      "|   (Open    | 0            |  Circuit)  | 0            |   String   | 0            |\n",
      "| (Reversed  | 0            | Polarity)  | 0            |            |              |\n",
      "|   total    | 1119         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[08/04 22:13:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/04 22:13:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[08/04 22:13:16 d2.data.common]: \u001b[0mSerializing 400 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/04 22:13:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.25 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/04 22:13:16 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "# Your dataset structure\n",
    "project_dir = \"training_data\"\n",
    "train_json = os.path.join(project_dir, \"data/train/annotations/result.json\")\n",
    "val_json = os.path.join(project_dir, \"data/valid/annotations/result.json\")\n",
    "train_imgs = os.path.join(project_dir, \"data/train/images\")\n",
    "val_imgs = os.path.join(project_dir, \"data/valid/images\")\n",
    "\n",
    "# Register dataset\n",
    "register_coco_instances(\"solar_train\", {}, train_json, train_imgs)\n",
    "register_coco_instances(\"solar_val\", {}, val_json, val_imgs)\n",
    "\n",
    "# Create config\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"solar_train\",)\n",
    "cfg.DATASETS.TEST = (\"solar_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 3000  # You can increase depending on dataset\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8  # 8 anomaly types\n",
    "cfg.OUTPUT_DIR = os.path.join(project_dir, \"output\")\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Start training\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7121c5-5da7-4a90-af00-90763a2c3a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361399b-1ace-4360-9575-1ea055786ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thermal-detector)",
   "language": "python",
   "name": "thermal-detector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
